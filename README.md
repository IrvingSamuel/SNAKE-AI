# Snake AI - Jogo da Cobrinha com Rede Neural IA AvanÃ§ada by Irving Samuel

Um jogo da cobrinha implementado em Python onde uma rede neural **avanÃ§ada** aprende a jogar usando aprendizado por reforÃ§o (Deep Q-Learning). O projeto foi **significativamente melhorado** com um sistema de estado expandido e arquitetura neural mais robusta.

## ğŸš€ Novas CaracterÃ­sticas (v2.0)

### ğŸ§  Sistema de Estado Expandido
- **28 caracterÃ­sticas** (expandido de 11) para decisÃµes mais inteligentes
- **DetecÃ§Ã£o de armadilhas** e planejamento espacial avanÃ§ado
- **AnÃ¡lise de densidade corporal** e espaÃ§os livres
- **EficiÃªncia de movimento** e otimizaÃ§Ã£o de trajetÃ³ria

### ğŸ—ï¸ Arquitetura Neural Melhorada
- **DQN de 3 camadas** com 512 neurÃ´nios (era LinearQNet com 256)
- **Sistema de recompensas inteligente** com mÃºltiplos critÃ©rios
- **Compatibilidade com modelos antigos** e migraÃ§Ã£o automÃ¡tica

## CaracterÃ­sticas Principais

- ğŸ Jogo da cobrinha clÃ¡ssico implementado com PyGame
- ğŸ§  **Rede neural avanÃ§ada DQN** que aprende usando Deep Q-Learning
- ğŸ¯ **IA superinteligente** com 28 caracterÃ­sticas de entrada
- ğŸ“Š Interface de visualizaÃ§Ã£o em tempo real do treinamento
- ğŸ“ˆ GrÃ¡ficos de performance e mÃ©tricas de aprendizado avanÃ§adas
- ğŸ® Modo manual para jogar vocÃª mesmo
- ğŸ¤– Modo automÃ¡tico para assistir a IA jogar
- ğŸš¨ **DetecÃ§Ã£o automÃ¡tica de armadilhas** e situaÃ§Ãµes perigosas
- ğŸ—ºï¸ **Planejamento espacial inteligente** e uso eficiente do espaÃ§o

## Tecnologias Utilizadas

- **Python 3.8+**
- **PyGame** - Interface grÃ¡fica do jogo
- **PyTorch** - ImplementaÃ§Ã£o da rede neural
- **Matplotlib** - GrÃ¡ficos e visualizaÃ§Ãµes
- **NumPy** - OperaÃ§Ãµes matemÃ¡ticas
- **OpenCV** - Processamento de imagem (opcional)

## Estrutura do Projeto

```
Snake/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ game/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ snake_game.py
â”‚   â”‚   â”œâ”€â”€ game_state.py
â”‚   â”‚   â””â”€â”€ constants.py
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ neural_network.py
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â””â”€â”€ training.py
â”‚   â”œâ”€â”€ interface/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ game_interface.py
â”‚   â”‚   â”œâ”€â”€ training_interface.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_processing.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ saved_models/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ training_data/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd Snake
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

3. Execute o jogo:
```bash
python main.py
```

## ğŸ¯ Performance e Resultados

### ğŸ“Š ComparaÃ§Ã£o de VersÃµes
| VersÃ£o | CaracterÃ­sticas | Arquitetura | Record MÃ¡ximo | Performance |
|--------|-----------------|-------------|---------------|-------------|
| v1.0 | 11 bÃ¡sicas | LinearQNet (256) | 85 pontos | Boa |
| **v2.0** | **28 expandidas** | **DQN (512)** | **100+** â­ | **Excelente** |

### ğŸ§  CaracterÃ­sticas do Estado Expandido (28)
1. **DetecÃ§Ã£o de Perigos** (3) - ObstÃ¡culos imediatos
2. **DireÃ§Ã£o Atual** (4) - OrientaÃ§Ã£o da cobra  
3. **LocalizaÃ§Ã£o da Comida** (4) - PosiÃ§Ã£o relativa do alimento
4. **Tamanho da Cobra** (1) - Comprimento normalizado
5. **Densidade Corporal** (4) - ConcentraÃ§Ã£o de segmentos por direÃ§Ã£o
6. **DistÃ¢ncias atÃ© Bordas** (4) - Proximidade com paredes
7. **EspaÃ§os Livres** (4) - Mobilidade disponÃ­vel por direÃ§Ã£o
8. **DetecÃ§Ã£o de Armadilhas** (2) - SituaÃ§Ãµes perigosas
9. **EficiÃªncia de Movimento** (2) - OtimizaÃ§Ã£o de trajetÃ³ria

## ğŸš€ Como Usar

### ğŸ“¥ InstalaÃ§Ã£o RÃ¡pida
```bash
# Clonar repositÃ³rio
git clone [url-do-repositorio]
cd Snake

# Instalar dependÃªncias
pip install -r requirements.txt

# Verificar instalaÃ§Ã£o
python main.py --check-deps
```

### ğŸ® Modos de ExecuÃ§Ã£o

#### ğŸ¤– Treinamento da IA (Recomendado)
```bash
# Treinamento com interface visual
python main.py --mode train-interface

# Treinamento rÃ¡pido por linha de comando
python main.py --mode train --games 2000

# Continuar treinamento de modelo existente
python main.py --mode train --model models/checkpoint_X.pth --games 1000
```

#### ğŸ•¹ï¸ Jogar
```bash
# Interface completa (Manual + IA)
python main.py --mode play

# Menu interativo (mais fÃ¡cil)
python main.py
```

### ğŸ¯ Controles da Interface
- **M** - Modo manual
- **A** - IA jogar automaticamente  
- **T** - Treinar IA
- **R** - Reset do jogo
- **SPACE** - Pausar/Despausar
- **ESC** - Sair

### ğŸ”§ MigraÃ§Ã£o de Modelos Antigos
Se vocÃª tem modelos da versÃ£o anterior (v1.0):
```bash
# Migrar modelos automaticamente
python migrate_models.py

# Treinar com modelo migrado
python main.py --mode train --model models/migration_checkpoint.pth
```

## âš™ï¸ ParÃ¢metros de Treinamento (v2.0)

### ğŸ§  Rede Neural
- **Entrada**: 28 caracterÃ­sticas (expandido de 11)
- **Arquitetura**: DQN com 3 camadas densas
- **NeurÃ´nios Ocultos**: 512 (expandido de 256)
- **SaÃ­da**: 3 aÃ§Ãµes (frente, direita, esquerda)

### ğŸ“š HiperparÃ¢metros
- **Learning Rate**: 0.001
- **Discount Factor (Î³)**: 0.9
- **Epsilon Start**: 1.0 â†’ **End**: 0.01 (exploraÃ§Ã£o â†’ exploitaÃ§Ã£o)
- **Memory Size**: 10.000 experiÃªncias
- **Batch Size**: 32
- **Target Update**: 100 episÃ³dios

### ğŸ’° Sistema de Recompensas
- **ğŸ Comida**: +20 (aumentado de +10)
- **ğŸ’€ Morte**: -15 (aumentado de -10)
- **ğŸ¯ Aproximar da comida**: +2
- **â†©ï¸ Afastar da comida**: -1
- **ğŸš¨ Risco de armadilha**: -8
- **ğŸ Bloqueio da cauda**: -4
- **ğŸ“ˆ Crescimento**: +0.5 por segmento

## ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## CrÃ©ditos

Inspirado no canal "Universo Programado" e na comunidade de IA em jogos.
